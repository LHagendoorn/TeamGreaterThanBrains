
SLURM job ID		Runtijd		Data								Batchsize		Resultaat
2042530				1 uur		train_reduced, 100x100				10 				2780 images
2042745				<10 min		too small 137 images				10				137 images

2043318				30 min		scratch, train_mediumsize 250x250	10				1360 images

Het kan zijn dat de grootte van de images uitmaakt voor hoelang hij draait. Zo ja: dan is hij een tikkie sneller op de scratch data. Een factor 2.5 ongeveer. Zo niet, dan maakt het niet uit of hij op scratch data draait ja of nee.

2043548				30 min		scratch, train_mediumsize 250x250	500				1000-1500 images (bij de 1000 gestopt)

2043664				<6 uur		kopieertaak uitvoeren: images verdelen in 10 directories


De jobs [fout]
2045282
2045283
2045284
2045285

DÃ© jobs
12 uur per stuk max. Train data.

2045295			featureExtract0
2045297			featureExtract1
2045298			featureExtract2
2045299			featureExtract3
2045300			featureExtract4
2045301			featureExtract5
2045302			featureExtract6
2045303			featureExtract7
2045304			featureExtract8
2045306			featureExtract9

Verwachte aantal uren: 8.4 x 16 x 10 = 1344
8.4 verwachte aantal uren dat de jobs runnen, Gebaseerd op eerste meting, hoe snel hij toen de images verwerkte. 
16 cores per node
10 jobs
Maximum aantal uren is dus: 12x16x10 = 1920 uur
Donderdag: 1258 uur gebruikt.

Vrijdag: 1259.5 uur gebruikt. Ik gok dat de uren nog niet bijgewerkt zijn...

De jobs
12 uur per stuk max. Test data.

2045692			0
	693			1
	694			2
	695			3
	696			4
	697			5
	698			6
	699			7
	700			8
	701			9